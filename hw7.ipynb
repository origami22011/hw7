{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.5417 - accuracy: 0.8004\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.3342 - accuracy: 0.8778\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.2824 - accuracy: 0.8963\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 9s 10ms/step - loss: 0.2506 - accuracy: 0.9090\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.2276 - accuracy: 0.9156\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2681 - accuracy: 0.9049\n",
      "Test accuracy on Fashion-MNIST: 0.9049000144004822\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 5s 2ms/step - loss: 1.2118 - accuracy: 0.7067\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.5404 - accuracy: 0.8506\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4260 - accuracy: 0.8794\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3767 - accuracy: 0.8931\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3467 - accuracy: 0.8997\n",
      "313/313 - 0s - loss: 0.2971 - accuracy: 0.9141 - 348ms/epoch - 1ms/step\n",
      "Test accuracy on MNIST: 0.9140999913215637\n",
      "Epoch 1/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.2085 - accuracy: 0.9236\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 7s 7ms/step - loss: 0.1914 - accuracy: 0.9288\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 8s 8ms/step - loss: 0.1769 - accuracy: 0.9349\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.1631 - accuracy: 0.9394\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.1509 - accuracy: 0.9436\n",
      "Training time for Fashion-MNIST:  38.33245491981506\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3245 - accuracy: 0.9057\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3075 - accuracy: 0.9107\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2926 - accuracy: 0.9153\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2787 - accuracy: 0.9196\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2655 - accuracy: 0.9227\n",
      "Training time for MNIST:  16.639249563217163\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "\n",
    "\n",
    "(train_images_fashion, train_labels_fashion), (test_images_fashion, test_labels_fashion) = fashion_mnist.load_data()\n",
    "train_images_fashion = train_images_fashion.reshape((60000, 28, 28, 1))\n",
    "train_images_fashion = train_images_fashion.astype('float32') / 255\n",
    "test_images_fashion = test_images_fashion.reshape((10000, 28, 28, 1))\n",
    "test_images_fashion = test_images_fashion.astype('float32') / 255\n",
    "model_fashion = models.Sequential()\n",
    "model_fashion.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model_fashion.add(layers.MaxPooling2D((2, 2)))\n",
    "model_fashion.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_fashion.add(layers.MaxPooling2D((2, 2)))\n",
    "model_fashion.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model_fashion.add(layers.Flatten())\n",
    "model_fashion.add(layers.Dense(64, activation='relu'))\n",
    "model_fashion.add(layers.Dense(10, activation='softmax'))\n",
    "model_fashion.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_fashion.fit(train_images_fashion, train_labels_fashion, epochs=5, batch_size=64)\n",
    "test_loss_fashion, test_acc_fashion = model_fashion.evaluate(test_images_fashion, test_labels_fashion)\n",
    "print('Test accuracy on Fashion-MNIST:', test_acc_fashion)\n",
    "(train_images_mnist, train_labels_mnist), (test_images_mnist, test_labels_mnist) = mnist.load_data()\n",
    "train_images_mnist, test_images_mnist = train_images_mnist / 255.0, test_images_mnist / 255.0\n",
    "train_images_mnist = train_images_mnist.reshape((60000, 28, 28, 1))\n",
    "train_images_mnist = train_images_mnist.astype('float32') / 255\n",
    "test_images_mnist = test_images_mnist.reshape((10000, 28, 28, 1))\n",
    "test_images_mnist = test_images_mnist.astype('float32') / 255\n",
    "model_mnist = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model_mnist.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model_mnist.fit(train_images_mnist, train_labels_mnist, epochs=5)\n",
    "test_loss_mnist, test_acc_mnist = model_mnist.evaluate(test_images_mnist,  test_labels_mnist, verbose=2)\n",
    "print('Test accuracy on MNIST:', test_acc_mnist)\n",
    "\n",
    "import time\n",
    "start_time_fashion = time.time()\n",
    "model_fashion.fit(train_images_fashion, train_labels_fashion, epochs=5, batch_size=64)\n",
    "end_time_fashion = time.time()\n",
    "training_time_fashion = end_time_fashion - start_time_fashion\n",
    "print('Training time for Fashion-MNIST: ', training_time_fashion)\n",
    "start_time_mnist = time.time()\n",
    "model_mnist.fit(train_images_mnist, train_labels_mnist, epochs=5)\n",
    "end_time_mnist = time.time()\n",
    "training_time_mnist = end_time_mnist - start_time_mnist\n",
    "print('Training time for MNIST: ', training_time_mnist)\n",
    "#Performance: On the Fashion-MNIST dataset, the model obtained an accuracy of roughly 90.50%, while on the MNIST dataset, \n",
    "#it obtained an accuracy of 91.41%. This suggests that the model's performance on the MNIST dataset was marginally superior \n",
    "#to that of the Fashion-MNIST dataset. This makes sense because, in general, people believe that the MNIST dataset presents \n",
    "#a simpler difficulty than the Fashion-MNIST dataset. \n",
    "\n",
    "#Training times: The MNIST dataset required roughly 16.64 seconds to train, but the Fashion-MNIST dataset required about 38.34 seconds. \n",
    "#This suggests that, in comparison to the MNIST dataset, the Fashion-MNIST dataset required more time for the model to train."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
