{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              528384    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1944065 (7.42 MB)\n",
      "Trainable params: 1944065 (7.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "782/782 [==============================] - 81s 101ms/step - loss: 0.4178 - accuracy: 0.8085 - val_loss: 0.3427 - val_accuracy: 0.8451\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 79s 101ms/step - loss: 0.2699 - accuracy: 0.8896 - val_loss: 0.3827 - val_accuracy: 0.8418\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 71s 91ms/step - loss: 0.1958 - accuracy: 0.9228 - val_loss: 0.4223 - val_accuracy: 0.8409\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 67s 86ms/step - loss: 0.1397 - accuracy: 0.9472 - val_loss: 0.4890 - val_accuracy: 0.8339\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.1095 - accuracy: 0.9586 - val_loss: 0.6134 - val_accuracy: 0.8330\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 70s 90ms/step - loss: 0.0733 - accuracy: 0.9738 - val_loss: 0.6527 - val_accuracy: 0.8310\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 65s 83ms/step - loss: 0.0632 - accuracy: 0.9781 - val_loss: 0.8610 - val_accuracy: 0.8250\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 0.0515 - accuracy: 0.9824 - val_loss: 0.7959 - val_accuracy: 0.8284\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 66s 85ms/step - loss: 0.0427 - accuracy: 0.9861 - val_loss: 0.7504 - val_accuracy: 0.8283\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 67s 85ms/step - loss: 0.0306 - accuracy: 0.9895 - val_loss: 0.9676 - val_accuracy: 0.8345\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.9676 - accuracy: 0.8345\n",
      "Test Loss: 0.9676257967948914\n",
      "Test Accuracy: 0.8345199823379517\n",
      "Successfully trained.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "words_per_review = 100\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=words_per_review)\n",
    "X_test = pad_sequences(X_test, maxlen=words_per_review)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=words_per_review))\n",
    "\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}\")\n",
    "print(f\"Test Accuracy: {results[1]}\")\n",
    "\n",
    "print(\"Successfully trained.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1411713 (5.39 MB)\n",
      "Trainable params: 1411713 (5.39 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "782/782 [==============================] - 65s 79ms/step - loss: 0.4166 - accuracy: 0.8071 - val_loss: 0.3589 - val_accuracy: 0.8484\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 62s 79ms/step - loss: 0.2662 - accuracy: 0.8928 - val_loss: 0.3636 - val_accuracy: 0.8443\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 61s 78ms/step - loss: 0.1982 - accuracy: 0.9229 - val_loss: 0.4734 - val_accuracy: 0.8321\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.1412 - accuracy: 0.9486 - val_loss: 0.4733 - val_accuracy: 0.8407\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 74s 94ms/step - loss: 0.1125 - accuracy: 0.9587 - val_loss: 0.4633 - val_accuracy: 0.8364\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 75s 96ms/step - loss: 0.0876 - accuracy: 0.9699 - val_loss: 0.5403 - val_accuracy: 0.8370\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 75s 96ms/step - loss: 0.0749 - accuracy: 0.9753 - val_loss: 0.5884 - val_accuracy: 0.8362\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 75s 96ms/step - loss: 0.0604 - accuracy: 0.9793 - val_loss: 0.6453 - val_accuracy: 0.8356\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 75s 96ms/step - loss: 0.0413 - accuracy: 0.9868 - val_loss: 0.6768 - val_accuracy: 0.8337\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 68s 87ms/step - loss: 0.0425 - accuracy: 0.9858 - val_loss: 0.7110 - val_accuracy: 0.8325\n",
      "782/782 [==============================] - 8s 11ms/step - loss: 0.7110 - accuracy: 0.8325\n",
      "Test Loss: 0.7109972834587097\n",
      "Test Accuracy: 0.8324800133705139\n",
      "Successfully trained.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "words_per_review = 100\n",
    "\n",
    "vocab_size = 10000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=words_per_review)\n",
    "X_test = pad_sequences(X_test, maxlen=words_per_review)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=words_per_review))\n",
    "\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}\")\n",
    "print(f\"Test Accuracy: {results[1]}\")\n",
    "print(\"Successfully trained.\")\n",
    "\n",
    "#Model with an additional Dense layer (4096 neurons):\n",
    "#Test Loss: 0.9676\n",
    "#Test Accuracy: 0.8345\n",
    "\n",
    "#Model without the first Dense layer:\n",
    "#Test Loss: 0.7110\n",
    "#Test Accuracy: 0.8325\n",
    "\n",
    "#These findings show that the test set loss is smaller for the model\n",
    "# without the first Dense layer (0.7110 vs 0.9676). This implies that there \n",
    "# may be less serious errors in the model's predictions. On the test set, the \n",
    "# accuracy of the model with the extra Dense layer is somewhat higher (0.8345 vs 0.8325). \n",
    "# This shows that the model's predictive ability may be enhanced by the additional Dense layer \n",
    "# by assisting it in identifying more intricate patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              528384    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 18725377 (71.43 MB)\n",
      "Trainable params: 18725377 (71.43 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "782/782 [==============================] - 139s 174ms/step - loss: 0.4406 - accuracy: 0.7921 - val_loss: 0.3826 - val_accuracy: 0.8418\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 149s 191ms/step - loss: 0.2763 - accuracy: 0.8884 - val_loss: 0.3604 - val_accuracy: 0.8420\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 141s 180ms/step - loss: 0.2023 - accuracy: 0.9196 - val_loss: 0.4491 - val_accuracy: 0.8311\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 136s 174ms/step - loss: 0.1431 - accuracy: 0.9460 - val_loss: 0.4532 - val_accuracy: 0.8369\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 140s 179ms/step - loss: 0.1020 - accuracy: 0.9622 - val_loss: 0.6574 - val_accuracy: 0.8210\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 138s 176ms/step - loss: 0.0854 - accuracy: 0.9700 - val_loss: 0.6081 - val_accuracy: 0.8248\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 147s 188ms/step - loss: 0.0620 - accuracy: 0.9774 - val_loss: 0.6922 - val_accuracy: 0.8306\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 135s 173ms/step - loss: 0.0428 - accuracy: 0.9856 - val_loss: 0.7761 - val_accuracy: 0.8308\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 139s 178ms/step - loss: 0.0472 - accuracy: 0.9842 - val_loss: 0.8031 - val_accuracy: 0.8130\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 138s 176ms/step - loss: 0.0345 - accuracy: 0.9889 - val_loss: 0.7419 - val_accuracy: 0.8298\n",
      "782/782 [==============================] - 15s 19ms/step - loss: 0.7419 - accuracy: 0.8298\n",
      "Test Loss: 0.7419235706329346\n",
      "Test Accuracy: 0.8297600150108337\n",
      "Successfully trained.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "words_per_review = 100\n",
    "vocab_size = 10000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=words_per_review)\n",
    "X_test = pad_sequences(X_test, maxlen=words_per_review)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=words_per_review))\n",
    "\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}\")\n",
    "print(f\"Test Accuracy: {results[1]}\")\n",
    "\n",
    "print(\"Successfully trained.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 100, 128)          1280000   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              528384    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1944065 (7.42 MB)\n",
      "Trainable params: 1944065 (7.42 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\ASUS\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "782/782 [==============================] - 69s 84ms/step - loss: 0.4270 - accuracy: 0.7977 - val_loss: 0.3601 - val_accuracy: 0.8447\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 64s 82ms/step - loss: 0.2702 - accuracy: 0.8892 - val_loss: 0.3413 - val_accuracy: 0.8531\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 64s 82ms/step - loss: 0.1913 - accuracy: 0.9253 - val_loss: 0.4197 - val_accuracy: 0.8459\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 65s 83ms/step - loss: 0.1376 - accuracy: 0.9473 - val_loss: 0.4300 - val_accuracy: 0.8388\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 68s 86ms/step - loss: 0.0984 - accuracy: 0.9636 - val_loss: 0.6743 - val_accuracy: 0.8345\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 64s 82ms/step - loss: 0.0726 - accuracy: 0.9735 - val_loss: 0.6861 - val_accuracy: 0.8338\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 64s 82ms/step - loss: 0.0569 - accuracy: 0.9803 - val_loss: 0.6850 - val_accuracy: 0.8260\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 65s 83ms/step - loss: 0.0494 - accuracy: 0.9828 - val_loss: 0.7806 - val_accuracy: 0.8351\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 66s 84ms/step - loss: 0.0371 - accuracy: 0.9877 - val_loss: 0.8956 - val_accuracy: 0.8288\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 70s 90ms/step - loss: 0.0358 - accuracy: 0.9876 - val_loss: 0.8387 - val_accuracy: 0.8310\n",
      "782/782 [==============================] - 9s 11ms/step - loss: 0.8387 - accuracy: 0.8310\n",
      "Test Loss: 0.8386818170547485\n",
      "Test Accuracy: 0.8309999704360962\n",
      "Successfully trained.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "\n",
    "words_per_review = 100\n",
    "vocab_size = 10000\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=words_per_review)\n",
    "X_test = pad_sequences(X_test, maxlen=words_per_review)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=words_per_review))\n",
    "\n",
    "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
    "\n",
    "model.add(Dense(units=4096, activation='relu'))\n",
    "\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "results = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Loss: {results[0]}\")\n",
    "print(f\"Test Accuracy: {results[1]}\")\n",
    "\n",
    "print(\"Successfully trained.\")\n",
    "#The model's prediction accuracy has marginally improved once the first Dense layer was eliminated.\n",
    "#  The accuracy was roughly 0.82976 before removal and climbed to nearly 0.83100 after removal.\n",
    "\n",
    "#But the test loss also went up, going from roughly 0.74192 to 0.83868. This indicates that although \n",
    "# the model's predictions are slightly more accurate on average, their overall level of confidence is \n",
    "# significantly lower.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
